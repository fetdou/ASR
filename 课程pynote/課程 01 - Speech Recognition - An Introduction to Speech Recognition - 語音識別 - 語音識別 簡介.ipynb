{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 align='center' style='color:purple'> Speech Recognition 語音識別 - 課程 01- An Introduction to Speech Recognition - 語音識別 簡介 - Python Tutorial</h1>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    "人工智慧-深度學習\n",
    "\n",
    "A.I Tutorials \n",
    "Deep Learning 教程 \n",
    "\n",
    "''' \n",
    "\n",
    "    04 - 課程    - Speech Recognition 語音識別\n",
    "\n",
    "         課程 00 - Speech Recognition \n",
    "                            - An Introduction to Speech Recognition - 語音識別 簡介 \n",
    "         \n",
    "         課程 00 - 語音識別  - 語音識別 簡介\n",
    "         \n",
    "                  \n",
    "                  -  程式範例   - 語音識別   - Speech Recognition                           \n",
    "                                              - Speech to Text \n",
    "\t\t\t\t                              - Text to Speech\n",
    "     \n",
    "'''  教程簡介 '''\n",
    "'''  語音識別 '''\n",
    "\n",
    "''' "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 資料準備\n",
    "\n",
    "    >> 你我互動學習園地\n",
    "        >> https://interactiveuandmetutorials.weebly.com/\n",
    "    \n",
    "    >> Python 程式語言 設計\n",
    "       >> https://pythonprogrammingtutorials.weebly.com/\n",
    "\n",
    "    \n",
    ">> 檔案路徑/\n",
    "    ├── 課程 01- An Introduction to Speech Recognition - 語音識別 簡介\n",
    "    ├\n",
    "    ├\n",
    "    ├──audio_files\\\n",
    "              ├──  harvard.wav\n",
    "              ├──  jackhammer.wav\n",
    "              ├──  eng.mp3\n",
    "              ├──  cn.mp3\n",
    "              ├──  cn5.mp3\n",
    "              ├──  hello4.mp3\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 磁碟區 C 中的磁碟是 OS\n",
      " 磁碟區序號:  68E3-32FD\n",
      "\n",
      " C:\\Users\\calvi\\OneDrive\\桌面\\課程SpeechRecogination\\課程1 的目錄\n",
      "\n",
      "2019/09/23  上午 10:15    <DIR>          .\n",
      "2019/09/23  上午 10:15    <DIR>          ..\n",
      "2019/09/23  上午 09:25    <DIR>          .ipynb_checkpoints\n",
      "2019/09/23  上午 10:11    <DIR>          audio_files\n",
      "               0 個檔案               0 位元組\n",
      "               4 個目錄  45,361,692,672 位元組可用\n"
     ]
    }
   ],
   "source": [
    "ddir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calvi\\OneDrive\\桌面\\課程SpeechRecogination\\課程1\\audio_files\n"
     ]
    }
   ],
   "source": [
    "cd audio_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 磁碟區 C 中的磁碟是 OS\n",
      " 磁碟區序號:  68E3-32FD\n",
      "\n",
      " C:\\Users\\calvi\\OneDrive\\桌面\\課程SpeechRecogination\\課程1\\audio_files 的目錄\n",
      "\n",
      "2019/09/23  上午 10:11    <DIR>          .\n",
      "2019/09/23  上午 10:11    <DIR>          ..\n",
      "2019/09/23  上午 10:11            10,762 cn.mp3\n",
      "2019/09/23  上午 10:11            26,540 cn5.mp3\n",
      "2019/09/23  上午 10:11             3,762 cnhello.mp3\n",
      "2019/09/16  上午 11:45            23,712 eng.mp3\n",
      "2018/05/02  下午 09:32         3,249,924 harvard.wav\n",
      "2019/09/23  上午 10:13            16,509 hello4.mp3\n",
      "2018/05/02  下午 09:32           600,204 jackhammer.wav\n",
      "               7 個檔案       3,931,413 位元組\n",
      "               2 個目錄  45,361,061,888 位元組可用\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calvi\\OneDrive\\桌面\\課程SpeechRecogination\\課程1\n"
     ]
    }
   ],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 磁碟區 C 中的磁碟是 OS\n",
      " 磁碟區序號:  68E3-32FD\n",
      "\n",
      " C:\\Users\\calvi\\OneDrive\\桌面\\課程SpeechRecogination\\課程1 的目錄\n",
      "\n",
      "2019/09/23  上午 10:15    <DIR>          .\n",
      "2019/09/23  上午 10:15    <DIR>          ..\n",
      "2019/09/23  上午 09:25    <DIR>          .ipynb_checkpoints\n",
      "2019/09/23  上午 10:11    <DIR>          audio_files\n",
      "               0 個檔案               0 位元組\n",
      "               4 個目錄  45,360,558,080 位元組可用\n"
     ]
    }
   ],
   "source": [
    "ddir"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 語音識別技術：過去，現在和未來\n",
    "    >> Speech Recognition Technology: The Past, Present, and Future\n",
    "    \n",
    "    >> 聲音是 未來 \n",
    "          >> 從 計算的角度來看\n",
    "              >> 語音識別 基本上\n",
    "                  >> 計算機軟件或 硬體設備是可以解碼 - 人類語音\n",
    "          >> 通常用於運行命令，操作設備或寫入，而無需使用鼠標，鍵盤或 按任何按鈕\n",
    "        \n",
    "    >> 今天，幾乎每項任務 都可以使用 語音命令 和 語音識別進行 自動化，如 安排時間\n",
    "        >> 這些任務可以由市場上現有的個人助理執行\n",
    "            >> 例如\n",
    "                >> Siri          - Apple\n",
    "                >> Cortana       - Microsoft\n",
    "                >> Alexia        - Amazon\n",
    "                >> Google        - Assistant     \n",
    "                >> Smart Speaker - Baidu  \n",
    "      \n",
    "      \n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 聲音是未來 -  Future\n",
    "    >> 語音識別技術的歷史\n",
    "        >> 語音識別技術\n",
    "\n",
    "    >> 人類學 的角度來看\n",
    "        >> 書面語言之前 很久就開發了口語\n",
    "        >> 每分鐘可以說 150個 單詞\n",
    "        >> 普通人在 60秒內可以 輸入40個單詞\n",
    "\n",
    "    >> 語音識別 - 技術的歷史\n",
    "        >> 可追溯到 18世紀的 重大突破\n",
    "            >> 為我們今天所知的 數字助理 提供了平台\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2160/0*MhrkCf5KbJX79YYy.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 語音識別中最早的進步主要集中在 元音 vowel sounds 的創建上\n",
    "\n",
    "    >> https://en.wikipedia.org/wiki/Vowel \n",
    "    \n",
    "    >> 作為 系統的基礎\n",
    "    >> 可以 學習解釋\n",
    "        >> 來自附近對話者 interlocutors 的 音素\n",
    "        >> 語音的構建塊- building blocks of speech\n",
    "\n",
    "    >> 發明者 受到他們所處的技術環境 的 阻礙\n",
    "        >> 只有 基本發明一台會 說話的機器\n",
    "     \n",
    "    >> 托馬斯愛迪生 Thomas Ediso \n",
    "        >> 19世紀末 開創的聽 寫 機器能夠 錄製語音 capable of recording speech \n",
    "        >> doctors and secretaries with a lot of notes to take on a daily basis\n",
    "       \n",
    "       >> 直到20 世紀 50年代，這種調查才會 導致真正的語音識別\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 貝爾實驗室創 Bell Labs \n",
    "    >> 建的Audrey機器 可以理解 0-9位數，準確率達到 90％\n",
    "    >> 有趣的是，這個準確度 只有在其發明者發言時才能記錄下來\n",
    "    >> 當其他人與奧黛麗交談時，在70％到80％之間\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/799/0*5xnYyyvT7hjQ_EX7.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 暗示了 語音識別的一些 持續挑戰\n",
    "    >> 每個人 都有不同的 聲音 和口語可能非常不一致\n",
    "    >> 與具有更高標準化水平的文本不同， 語音詞根據區域 方言，速度，重點\n",
    "    >> 甚至 社會階級 和 性別而有很大差異\n",
    "    \n",
    "    >> 因此，縮放任何語音識別系統 scaling any speech recognition system \n",
    "        >> 一直是一個重大障礙\n",
    "\n",
    ">> 亞歷山大·威貝爾（Alexander Waibel）\n",
    "    >> 曾在 卡內基梅隆大學（Carnegie Mellon University）\n",
    "    >> 開發的機器 Harpy上工作\n",
    "        >> 可以 理解 超過1000個單詞-  1,000 words\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 20世紀90年代\n",
    "    >> 即使是最成功的系統也基於模板匹配 template matching\n",
    "    >> 其中 聲波 sound waves 將被轉換為一組數 字並 存儲\n",
    "        >> numbers and stored\n",
    "    \n",
    "    >> 當相同的聲音進入機器時，這些將被觸發\n",
    "    >> 當然，這意味著人們 必須非常清楚，緩慢地說話\n",
    "        >> 並且在 沒有背景噪音的環境中才能很好地 識別聲音\n",
    "        \n",
    "        \n",
    "    >> IBM Tangora於20世紀 80年代中期發布\n",
    "        >> 以當時世界上最快的打字員Albert Tangora的名字命名\n",
    "        >> 可以 適應 發言人的聲音\n",
    "            >> 仍然需要緩慢，清晰的語音和 無背景噪音\n",
    "            >> 使用隱馬爾可夫模型通過數據聚類\n",
    "                >> 基於最近模式的即將到來的音素預測提高了靈活性   \n",
    "       >> 20分鐘的 訓練數據（以錄製的語音形式）\n",
    "           >> 但Tangora可以識別多達20,000個英語單詞和一些完整的句子 \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/664/0*Ry_6Xapk_pUW0vku.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 種子播種在這裡用於 語音識別 voice recognition\n",
    "    >> 這是該領域最重要和最重要的 發展之一\n",
    "\n",
    ">> 1997年\n",
    "    >> 世界上第一個 連續語音識別器 - continuous speech recognizer\n",
    "        >> 即一個不再需要在每個單詞之間停頓\n",
    "    >> 才以\n",
    "        >> Dragon's NaturallySpeaking軟件的形式發布\n",
    "        >> 能夠每分鐘理解 100個單詞\n",
    "        >> 今天仍然在使用（雖然是升級形式）\n",
    "        >> 並且由於醫生的註釋目的而受到青睞\n",
    "        \n",
    "        \n",
    "   >> 機器學習\n",
    "       >> 在本世紀 提供了 大部分語音識別 突破\n",
    "       >> Google\n",
    "           >> 將最新技術 與 基於雲計算的 強大功能相結合\n",
    "               >> 共享數據並提高 機器學習算法的準確性     \n",
    "\n",
    "    >> 導致2008年\n",
    "        >> 推出適用於 iPhone\n",
    "            >> Google Voice Search 應用程序\n",
    "            \n",
    "        >> Siri之後\n",
    "            >> 微軟 推出了Cortana\n",
    "            >> 亞馬遜推出了Alexa    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 語音識別 - 黑盒子\n",
    ">> Speech Recognition Machine Learning isn’t always a Black Box\n",
    "\n",
    "    >> Machine Learning / neural network\n",
    "        >> train it to produce text\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2458/1*nJNxFmJaHxyJTtVFkhGTlg.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 最大的問題是語音速度不同\n",
    "    >> 一個人可能會很快說 - 你好\n",
    "    >> 而另一個人可能會非常緩慢地說\n",
    "        >>  heeeelllllllllllllooooo！ \n",
    "        >> 從而生成一個包含更多數據的更長聲音文件\n",
    "        >> 兩個聲音文件都應該被識別為完全相同的文本 Text  - 你好！\n",
    "            >> 自動將各種長度的音頻文件對齊到固定長度的文本 Text 結果\n",
    "                >> 是相當困難的\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> Speech recognition 語音識別\n",
    "    >> 聲音變成 - 位元 Bits\n",
    "    >> comverting Sounds into Bits\n",
    "\n",
    "    >> 語音識別的第一步顯\n",
    "        >> 需要將 聲波輸入  電腦 / 計算機\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1370/1*fyZ9oVvMXJ2Y5oMrh_5nkA.jpeg\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    "    >> 語音識別 的第一步\n",
    "        >> 需要將聲波 輸入  電腦 / 計算機\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/726/1*zY1qFB9aFfZz66YxxoI2aw.gif\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 從計算的角度來看\n",
    "    >> 語音識別基本上是可以 解碼人類語音的 計算機軟件或 硬件設備\n",
    "    >> 通常用於運行命令，操作設備或寫入，而無需使用鼠標，鍵盤或按任何按鈕\n",
    "    >> 今天\n",
    "        >> 幾乎每項任務都可以使用語音命令和語音識別進行自動化\n",
    "        >> 從美容沙龍到安排時間。這些任務可以由市場上現有的個人助理執行\n",
    "            >> 例如\n",
    "                >> Siri          - Apple\n",
    "                >> Cortana       - Microsoft\n",
    "                >> Alexia        - Amazon\n",
    "                >> Google        - Assistant     \n",
    "                >> Smart Speaker - Baidu \n",
    "                \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1370/1*fyZ9oVvMXJ2Y5oMrh_5nkA.jpeg\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 聲音是以 波浪的形式 傳播的\n",
    "    >> 如何將 聲波轉換為 數字？\n",
    "    >> 讓我用這個聲音片段\n",
    "        >>  \" 你好 \" \n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound('audio_files\\cnhello.mp3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i2.wp.com/blogit.itu.dk/ethos/wp-content/uploads/sites/14/2017/09/speechrecognition.png?resize=1024%2C351&ssl=1\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2535/1*6_q1VIVJuavYa-9Uby_L-A.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 聲波是 一維的\n",
    "    >> 在每個時刻\n",
    "        >> 都有一個基於 波浪高度的 單一值\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/3573/1*dqWhWUIzIyOLIqVReTBaiA.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 聲波轉換為數字，我們只需在等 間距點 記錄波 的高度\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2000/1*dICZCcmEm_EWWx0yA6B3Cw.gif\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 抽樣  - Sampling\n",
    "    >> 每秒讀取數千次讀數 並記錄表示該時間點聲波高度的數字\n",
    "        >> 這基本上都是一個未壓縮的.wav音頻文件\n",
    "        >> CD質量 音頻採樣為 44.1khz（每秒讀數為 44,100）- sampling rate\n",
    "        >> 語音識別，16khz（每秒16,000個 樣本）的採樣率 - sampling rate\n",
    "            >> 足以覆蓋人類語音的 頻率範圍。\n",
    "            >> 每秒 16,000次採樣我們的“ Hello” 聲波 sound wave\n",
    "                >> 前 - 100 個樣本 100 samples\n",
    "    \n",
    "    >> 每個數字表示聲波的幅度為1/16000秒 的 間隔\n",
    "        >> Sound Wave at 1/16000th of a second intervals\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/4068/1*BG4iFbx7qhb5v_JTr958PQ.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2000/1*KkWfr3a6HtRSZ8-4LUw0kg.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 奈奎斯特定理 -  Nyquist theorem\n",
    "    >> 我們知道我們可以使用 數學來完美地 重建間隔 樣本中的 原始聲波 \n",
    "    >> 只要採樣的速度至少是我們想要記錄的最高頻率的兩倍\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> Speech - Text \n",
    "    >> 語音 -  文本 / 文字\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i1.wp.com/www.simplifiedpython.net/wp-content/uploads/2018/07/speech-recognition-python.png?w=556&ssl=1\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://cdn.ttgtmedia.com/rms/onlineImages/crm-voice_recognition_mobile.png\" width=\"50%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 預處理 -  採樣 聲音數據\n",
    "    >>  Pre-processing our Sampled Sound Data\n",
    "    >> 有一個數字數組，每個數字代表聲波的振幅，以1/16,000秒為 間隔\n",
    "    \n",
    "    >>音頻數據 進行一些 預處理\n",
    "        >> 這些數字 - 輸入神經網絡\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i1.wp.com/www.simplifiedpython.net/wp-content/uploads/2018/07/speech-recognition-python-1.png?w=682&ssl=1\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 採樣音頻分組 為 20毫秒長的塊\n",
    "    >> 前 20毫秒音頻（即我們的前 320個 樣本）\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/4055/1*_qUExEvllTKFhsrITxsa-A.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 數字 繪製為簡單的折線圖 - simple line graph\n",
    "    >> 20 millisecond period of time\n",
    "    >> 20毫秒的時間內粗略估計原始聲波\n",
    "    \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2024/1*ZMxcyjNFqIOVzJRM9BCMWw.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 使神經網絡 更容易處理 這些數據\n",
    "    >> neural network to process\n",
    "    >> 將把這個複雜的聲波分解成它的 組成部分\n",
    "        >> complex sound wave into it’s component parts\n",
    "    >> 將打破低音調部分 low-pitched parts ，下一個最低音調部分，等等\n",
    "    >> 然後通過計算每個 頻段（從低到高）的能量，\n",
    "    >> 為此 音頻片段  audio snippet 創建了各種指紋 fingerprint \n",
    "\n",
    "\n",
    ">> 傅立葉變換的數學運算來完成此操作。它將復雜的聲波分解成簡單的聲波。一旦我們獲得了那些單獨的聲波，我們就會計算每個聲波中包含多少能量\n",
    "\n",
    "    >> https://en.wikipedia.org/wiki/Fourier_transform\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/3975/1*2Vg8z3--moE-E7KybJlUPg.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 繪製為圖表時\n",
    "\n",
    "    >> 20毫秒 聲音片段 - 具有大量的 低頻能量\n",
    "        >> 較高頻率下沒有太多能量\n",
    "            >> 典型的“- 男性”聲音\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1901/1*A4CxgdyqYd_nrF3e-7ETWA.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 頻譜圖 - spectrogram\n",
    ">> 每20毫秒 的音頻塊 上 重複這個過程\n",
    "    >> 得到一個 頻譜圖 \n",
    "    >> 每個列從左到右是一個20ms的塊\n",
    "    \n",
    "\n",
    "    >> 音頻數據中 - 看到音符和其他音高模式\n",
    "    >>  musical notes and other pitch patterns in audio data\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2421/1*bhd7B-s-Qnds3HGV6LOo8A.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 短的聲音 識別字符\n",
    "    >> Recognizing Characters from Short Sounds\n",
    "\n",
    ">> 音頻格式 易於處理\n",
    "    >> 提供給深度神經網絡 - deep neural network\n",
    "    >> 神經網絡- 輸入將是 20毫秒 的音頻塊\n",
    "    >> 對於 每個小音頻 切片\n",
    "        >> 將嘗試找出與 當前所說聲音- 相對應的字母\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://i1.wp.com/www.simplifiedpython.net/wp-content/uploads/2018/07/speech-recognition-python-1.png?w=682&ssl=1\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1989/1*z1Nf0ES1YVUfdZZGW0PSdQ.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 遞歸/ 循環神經網絡 \n",
    "    >> recurrent neural network \n",
    "    >> 預測的 每個字母都 會影響它預測下一個字母 的可能性\n",
    "    \n",
    "    >> 通過神經網絡（一次一個塊）運行我們的 整個音頻 剪輯之後\n",
    "        >> 最終會 得到每個音頻塊 到該塊中\n",
    "        >> 最有可能說出的字母的映射 mapping\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2500/1*d1ktMdOnFOJRKKyjFP6sqQ.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 神經網絡 預測\n",
    "    >> 一個可能的文字 是 -\n",
    "        >> HHHEE_LL_LLLOOO\n",
    "    >> 有可能認為\n",
    "        >> HHHUU_LL_LLLOOO\n",
    "            >> 有可能 - AAAUU_LL_LLLOOO\n",
    "    >> 有一些步驟來 清理這個輸出\n",
    "        >> 首先\n",
    "            \n",
    "            \n",
    "    >> 將替換任何重複字符的單個字符  : \n",
    "\n",
    "        >> HHHEE_LL_LLLOOO 變為 >> HE_L_LO\n",
    "        >> HHHUU_LL_LLLOOO 變為 >> HU_L_LO\n",
    "        >> AAAUU_LL_LLLOOO變為  >> AU_L_LO\n",
    "\n",
    "    >> 然後刪除任何空白：\n",
    "    \n",
    "        >> HE_L_LO 變為  >> HELLO\n",
    "        >> HU_L_LO 變成  >> HULLO\n",
    "        >> AU_L_LO 變為  >> AULLO\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/2421/1*bhd7B-s-Qnds3HGV6LOo8A.png\" width=\"100%\"> "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 當前 語音識別領域\n",
    "    >> Speech Recognition Landscape\n",
    "    \n",
    "    \n",
    "    >> 智能 / 智慧型手機\n",
    "        >> 最初是 Siri和Cortana等 數字助理的唯一居住地\n",
    "            >> 過去幾年中已經分散\n",
    "        >> 目前\n",
    "            >> 重點主要\n",
    "                >> 放在 語音激活的家庭揚聲器上 voice-activated home speakers\n",
    "           \n",
    "            >> 這些 揚聲器/ 喇叭-speakers是 智能設備激增的門戶\n",
    "                >> 可以在廣泛的 - 物聯網 IoT Internet of Thing -進行分類\n",
    "                >> Google Home或Amazon Echo\n",
    "                >> 已經可以用於控制 大量支持互聯網 Internet-enabled devices 的設備\n",
    "                >> 到2020年\n",
    "                    >> 還有更多的設備可以加入\n",
    "                >> 這些設備包括智能冰箱 mart fridges\n",
    "                    >> 耳機 headphones，鏡子 mirrors 和煙霧報警器 smoke alarms\n",
    "                >> 以及 third-party integrations \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> GOOGLE Home\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://brain-images-ssl.cdn.dixons.com/1/4/10161441/u_10161441.jpg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> Apple - Siri Speaker\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://www.patentlyapple.com/.a/6a0120a5580826970c01b8d2e6f2c9970c-800wi\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 亞馬遜 - Amazon Echo - Alexa\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://fc.bnext.com.tw/wp-content/uploads/2019/09/img-1546900059-78620@600.png\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://miro.medium.com/max/1200/0*Ub31UBdmA3Xx9eri.jpg\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> Baidu Smart Speaker - 百度 智能音箱\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://venturebeat.com/wp-content/uploads/2018/08/Moto-AI-Speakers-Amazon-Echo13.png?fit=430%2C430&strip=all\" width=\"50%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 程式範例"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 導入 相關 函式庫 \n",
    "   >> import relative Library\n",
    "   \n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> SpeechRecognition 語音識別 - 函式庫 Library\n",
    "    >> https://pypi.org/project/SpeechRecognition/\n",
    "    >> pip install SpeechRecognition\n",
    "\n",
    "    >> https://github.com/Uberi/speech_recognition#readme\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.8.1\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "print(sr.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> record()\n",
    "    >> 音頻文件中獲取數據\n",
    "\n",
    "recognize_bing(): Microsoft Bing Speech\n",
    "recognize_google(): Google Web Speech API\n",
    "recognize_google_cloud(): Google Cloud Speech - requires installation of the google-cloud-speech package\n",
    "recognize_houndify(): Houndify by SoundHound\n",
    "recognize_ibm(): IBM Speech to Text\n",
    "recognize_sphinx(): CMU Sphinx - requires installing PocketSphinx\n",
    "recognize_wit(): Wit.ai\n",
    "\n",
    "    >> Recognizer API主要用於  - 識別語音\n",
    "        >> 每個API都有多個設置 和 功能來識別音頻源的語音\n",
    "    >> recognition_sphinx()\n",
    "        >> 可以 與 CMU Sphinx引擎 offline 工作\n",
    "        >> 其他六個需要連接online 到 Internet\n",
    "        \n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 支持的文件類型。\n",
    "    >> peechRecognition目前支持以下文件類型。\n",
    "\n",
    "        >> WAV：必須是PCM / LPCM格式。\n",
    "        >> AIFF\n",
    "        >> AIFF-C\n",
    "        >> FLAC：必須是原始的FLAC格式\n",
    "            >> OGG-FLAC格式不可用\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio_files\\harvard.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvard = sr.AudioFile('audio_files\\harvard.wav')\n",
    "with harvard as source:\n",
    "   audio = r.record(source)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> record()函數\n",
    "    >> 將整個文件數據讀入AudioData 實例\n",
    "        >> 這可以通過檢查音頻類型\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.AudioData"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stale smell of old beer lingers it takes heat to bring out the odor a cold dip restores health and zest a salt pickle taste fine with ham tacos al Pastore are my favorite a zestful food is be hot cross bun'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 偏移和持續時間捕獲音頻剪輯\n",
    "\n",
    ">>> with harvard as source:\n",
    "... audio = r.record(source, duration=4)\n",
    "...\n",
    ">>> sr.recognize_google(audio)\n",
    "'the stale smell of old beer lingers'\n",
    "\n",
    ">> 前四秒音頻將保存在 audio1中，後四秒鐘音頻將保存在 audio2中\n",
    "\n",
    ">>> with harvard as source:\n",
    "... audio1 = sr.record(source, duration=4)\n",
    "... audio2 = sr.record(source, duration=4)\n",
    "...\n",
    ">>> sr.recognize_google(audio1)\n",
    "'the stale smell of old beer lingers'\n",
    ">>> sr.recognize_google(audio2)\n",
    "'it takes heat to bring out the odor a cold dip'\n",
    "\n",
    ">> 偏移設置為4秒，並記錄持續時間3秒\n",
    "\n",
    ">>> with harvard as source:\n",
    "... audio = sr.record(source, offset=4, duration=3)\n",
    "...\n",
    ">>> recognizer.recognize_google(audio)\n",
    "'it takes heat to bring out the odor'\n",
    "\n",
    ">> 事先知道文件的 語音結構時\n",
    "    >> 偏移和持續時間關鍵字參數對於分割音頻文件非常有用\n",
    "    >> 但不准確的使用會導致轉錄不良\n",
    "\n",
    ">>> with harvard as source:\n",
    "... audio = r.record(source, offset=4.7, duration=2.8)\n",
    "...\n",
    ">>> recognizer.recognize_google(audio)\n",
    "\n",
    "\n",
    ">> 上面的程序記錄從4.7秒開始\n",
    "    >> 因此短語“it t”中的短語“它需要加熱來帶出氣味”並沒有記錄\n",
    "        >> 並且API只獲得輸入“akes heat”並匹配結果“Mesquite” \n",
    "        >> 類似地，API僅在錄音結束時\n",
    "            >> 為“冷浸恢復健康和熱情”這一短語捕獲了“a co”\n",
    "            >> 並且與“Aiko”不匹配\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# audio_files\\jackhammer.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "harvard = sr.AudioFile('audio_files\\jackhammer.wav')\n",
    "with harvard as source:\n",
    "   audio = r.record(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speech_recognition.AudioData"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(audio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the snail smell of old beer drinkers'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "https://www.code-learner.com/python-speech-recognition-introduction-and-practice/"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 噪聲 對 語音識別的 影響\n",
    "    >> 現實世界中存在噪聲，並且所有錄音都有 一定程度的噪音\n",
    "    >> 未經處理的噪音會破壞語音識別應用的準確性\n",
    "    \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> The Microphone input\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    ">> 使用 麥克風\n",
    "    >> SpeechRecognizer 使用 麥克風\n",
    "    >> 安裝 PyAudio\n",
    "        >>  pip install pyaudio\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr\n",
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "mic = sr.Microphone()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Microsoft 音效對應表 - Input',\n",
       " 'Microphone (sabinetek usb audio',\n",
       " 'Microphone (Realtek High Defini',\n",
       " 'Microsoft 音效對應表 - Output',\n",
       " 'Speakers (Realtek High Definiti',\n",
       " '喇叭 (sabinetek usb audio)',\n",
       " 'Microphone (Realtek HD Audio Mic input)',\n",
       " 'Speakers (Realtek HD Audio output)',\n",
       " 'Stereo Mix (Realtek HD Audio Stereo input)',\n",
       " 'Speakers (sabinetek usb audio)',\n",
       " 'Microphone (sabinetek usb audio)']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sr.Microphone.list_microphone_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mic as source:\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello everybody good day'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> 處理環境噪聲 \n",
    "    >> adjust_for_ambient_noise() - 環境噪音\n",
    "    >> 調用Recognizer類的adjust_for_ambient_noise()函數\n",
    "    >> 其行為與對噪聲音頻文件的行為相同\n",
    "    >> 由於麥克風輸入聲音的可預測性低於音頻文件\n",
    "    >> adjust_for_ambient_noise() 默認調整為1秒長的音頻源\n",
    "        >> 認為此時間太長，可以使用duration參數進行調整\n",
    "        \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mic as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello good day'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " '''\n",
    "\n",
    ">> 難以識別的過程語音\n",
    "    >> 麥克風中輸入一些難以理解的噪音\n",
    "    >> API無法與文本匹配的音頻將導致 UnknownValueError\n",
    "        >> 因此，try 和 except塊經常用於解決此問題。API盡力將任何聲音轉換為文本\n",
    "        >> 例如可能被識別為“如何”的短咕嚕聲\n",
    "            >> 或者可能被轉換為文本並導致異常的咳嗽，掌聲或舌頭咔嗒聲\n",
    "            \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    ">> Text To Speech \n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the stale smell of old beer lingers it takes heat to bring out the odor a cold dip restores health and zest a salt pickle taste fine with ham tacos al Pastore are my favorite a zestful food is be hot cross bun'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "\n",
    "r = sr.Recognizer()\n",
    "\n",
    "with sr.AudioFile('audio_files\\harvard.wav') as source:\n",
    "    audio = r.record(source)\n",
    "\n",
    "r.recognize_google(audio, language='eg') # language='zh-tw' -> 繁體中文"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = pyttsx3.init()\n",
    "engine.say(\"I will speak this text\")\n",
    "engine.say(\"台灣是個美麗的寶島\")\n",
    "engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gtts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.4'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gtts.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = \" 你好 \"\n",
    "obj = gTTS(text = tw, slow = False, lang = 'zh-tw') ## en \n",
    "obj.save('audio_files\\cnhello.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = \" 台灣是個美麗的寶島\"\n",
    "obj = gTTS(text = tw, slow = False, lang = 'zh-tw') ## en \n",
    "obj.save('audio_files\\cn.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tw = \" 強！郭婞淳挺舉140公斤 破世界紀錄奪金 \"\n",
    "obj = gTTS(text = tw, slow = False, lang = 'zh-tw') ## en \n",
    "obj.save('audio_files\\cn5.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import playsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simpleaudio as sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_obj = sa.WaveObject.from_wave_file(\"audio_files\\harvard.wav\") # harvard.wav\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_obj = sa.WaveObject.from_wave_file(\"audio_files\\jackhammer.wav\") # jackhammer.wav\n",
    "play_obj = wave_obj.play()\n",
    "play_obj.wait_done()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound('audio_files\\cn5.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound('audio_files\\cn.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from playsound import playsound\n",
    "playsound('audio_files\\cnhello.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition\n",
    "r = speech_recognition.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with speech_recognition.Microphone() as source:\n",
    "    r.adjust_for_ambient_noise(source)\n",
    "    audio = r.listen(source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'大家好'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.recognize_google(audio, language='zh-TW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtts import gTTS\n",
    "tts = gTTS(text='大家好 !  祝大家有個美好的一天', lang='zh-tw')\n",
    "tts.save(\"audio_files\\hello4.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pygame 1.9.6\n",
      "Hello from the pygame community. https://www.pygame.org/contribute.html\n"
     ]
    }
   ],
   "source": [
    "from pygame import mixer\n",
    "mixer.init()\n",
    "mixer.music.load('audio_files\\hello4.mp3')\n",
    "mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "def speak(sentence):\n",
    "    with tempfile.NamedTemporaryFile(delete=True) as fp:\n",
    "        tts = gTTS(text=sentence, lang='zh-tw')\n",
    "        tts.save(\"{}.mp3\".format(fp.name))\n",
    "        mixer.music.load('{}.mp3'.format(fp.name))\n",
    "        mixer.music.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak('大家好!祝大家有個美好的一天')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "'''\n",
    "\n",
    "    >> pip install pygame \n",
    "        >> https://www.pygame.org/\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import speech_recognition\n",
    "\n",
    "def listenTo():\n",
    "    r = speech_recognition.Recognizer()\n",
    "\n",
    "    with speech_recognition.Microphone() as source:\n",
    "        r.adjust_for_ambient_noise(source)\n",
    "        audio = r.listen(source)\n",
    "\n",
    "    return r.recognize_google(audio, language='zh-TW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "from gtts import gTTS\n",
    "from pygame import mixer\n",
    "mixer.init()\n",
    "\n",
    "def speak(sentence):\n",
    "    with tempfile.NamedTemporaryFile(delete=True) as fp:\n",
    "        tts = gTTS(text=sentence, lang='zh-tw')\n",
    "        tts.save(\"{}.mp3\".format(fp.name))\n",
    "        mixer.music.load('{}.mp3'.format(fp.name))\n",
    "        mixer.music.play()\n",
    "        \n",
    "speak('大家好!祝大家有個美好的一天')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak(listenTo())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "Answer = {\n",
    "  '你好嗎'    : '我很好',\n",
    "  '你很帥'    : '謝謝啦 !',\n",
    "  '再見了'    : '下次見了! 再聊 ! 拜拜'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "speak(Answer.get(listenTo(), '對不起，聽不清楚 ! 請再說一變，謝謝啦 ! 再回答你'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
